{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference b/w DNNs and CNNs:\n",
    "\n",
    "Recall that in __DNN__ each __Neuron__ is connected to all the __Neurons__ of the next layer. But, in __CNN__ the approach is slightly different.\n",
    "\n",
    "__CNNs__ are more inspired by __Visual Cortex__ of human brain. A research showd that __Visual Cortex__ makes the shape of an image in human brain, by distributing the region of an image to multiple group of __Neurons__ which are responsible to decode the information of that particular part of the image. And collaborately they end up making the image of a particular image.\n",
    "\n",
    "That's how __CNNs__ also work. Each __Neuron__ is connected to a smaller number of nearby units in the next layer, which share the information with rest of the __Neurons__ in same way connected with the network which is directly inspried by the _Biological Visual Cortex_\n",
    "\n",
    "So, the question arises, _WHY BOTHER WITH A CNN INSTEAD OF DNN??_\n",
    "\n",
    "This is because if we consider the __MNIST__ dataset we having 55K images each having 784 pixels. Normally in real scenarios we have at least __256 by 256__ pixels per image. That makes computation and scalability a lot more difficult! So in order to deal with all these issues, we use __Convolution Technique__.\n",
    "\n",
    "__Convolution__ also have a major advantage for __Image Processing__, where pixels nearby to each other are much more correlated to each other for image detection. Each __CNN__ layer looks at an increasingly larger part of an image. __CNN__ also helps with __Regularization__ limiting the search of __weights__ to the __size__ of the convolution.\n",
    "\n",
    "Let's explore how the __CNN__ relates to __Image Recognition__\n",
    "\n",
    "We start with the __input layer__ (the image itself). Mind you, __Convolutional layers__ are only connected to pixels in their respective fields. This leads to running into a possible issue for edge Neurons, as it's approaches the edges the Neurons gets lower in number for the layer. There may not be any __Input Neurons__ for the input data. \n",
    "\n",
    "We can fix this issue by _adding a padding of zeros around the image_ genrally known as __Padding__. \n",
    "\n",
    "Let's now begin to understand **1-D** Convolution and then we'll expand the idea to __2-D__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-D Convolution:\n",
    "\n",
    "\n",
    "$y = w_{1}x_{1}$ + $w_{2}x_{2}$: if $w_{1} and w_{2}$ equals to (1,-1), then\n",
    "$y = x_{1} - x_{2}$\n",
    "\n",
    "So, what would be the _maximum value for y??_\n",
    "And that would be when $(x_{1}, x_{2}) = (1,0)$ respectively, which is basically an example of a __Filter__ that is specifically designed for __Image detection__\n",
    "Because edges, when we represent them as pixels just represent a large difference in the actual darkness of the two pixels that are right next to each other. Essentially describing an __Edge__.\n",
    "\n",
    "Another important idea in __CNNs__ is __Striding the Filters__. This is when we __stride__ the set of weights or in general (the neurons) or filters along the next __CNN Layer__ i.e if we we are going __2-Units__ at a time, this is called __Stride of 2__ and same for other units.\n",
    "\n",
    "For simplicity, we begin to describe and visualize these sets of Neurons and blocks instead, where the number of units (Neurons) would be one dimension and filters be the the other one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve1D(lst1, lst2):\n",
    "    \n",
    "    \"\"\"\n",
    "    simple mathematical 1-D convolution example!\n",
    "    \"\"\"\n",
    "    \n",
    "    convolve_sum = 0\n",
    "    \n",
    "    for i in lst1:\n",
    "        for j in lst2:\n",
    "            convolve_sum += (i * j)\n",
    "    \n",
    "    return 'Convolution sum: ' + str(convolve_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Convolution sum: 36'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1 = [1,2,3]\n",
    "lst2 = [1,2,3]\n",
    "\n",
    "convolve1D(lst1, lst2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-D Convolution:\n",
    "\n",
    "Let's now expand these concepts to __2-D__ Convolution, since we'll mainly be dealing with images.\n",
    "\n",
    "In __2-D Convolution__ instead of being 1-D, it's 2-D where we have __height__ and __width__ to the image itself. And than for that next layer we have this __Tensor__ with the __No. of filters__ and __No. of units__ for the __width__ by the __No. of units__ for the __height__ and we have this 3-D __Tensor__ object.\n",
    "\n",
    "And we can see that the sub-sections are going to be directly related to this __Tensor__. \n",
    "\n",
    "For a __GrayScale__ we have only one color channel, but for the __Colored images__ we have 3 Channels (Red, Green and Blue).\n",
    "\n",
    "\n",
    "## Pooling & Sub-Sampling:\n",
    "\n",
    "__Pooling__ layers are used to __Sub-sample__ the input image which reduces the __memory usage__ and computer load, as well as reduces the number of parameters.\n",
    "\n",
    "Let's imagine a layer of pixels in our input image. Each Pixel has some sort of value representing it's __Darkness__ noramlly in a range of 0-1. And the way __Pooling__ works is we create a __2 by 2__ pool of Pixels, known as __Kernal__, and then we evaluate the maximum value, which means __only the maximum value among all the values will proceed to the next layer__. \n",
    "\n",
    "We continue moving over by stride and calculating the maximum value, and proceeding it to the next layer. This maximum value is the representation of the whole __Kernal__.\n",
    "\n",
    "And it doesn't necessoraly have to be __2 by 2__ we can take any size pool we want. This __Pooling layer__ will end up removing a lot of information, even a small __pooling kernal__ of 2*2 with the stride of 2 will remove 75% of the input data.\n",
    "\n",
    "\n",
    "## Dropout:\n",
    "\n",
    "Another common technique deployed with __CNN__ is called __Dropout__. It can be thought of as a form of __Regularization__ to help prevent __Overfitting__. During training units are randomly dropped along with their connections which helps prevent units from __co-adapting__ too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolve2D():\n",
    "    \n",
    "    \"\"\"\n",
    "    A general example of 2-D convolution with a stride of 1\n",
    "    \"\"\"\n",
    "    pooled_image = []\n",
    "    image = np.linspace(0.1,1,9).reshape(3,3) # take a randome 3*3 array for an image\n",
    "    \n",
    "    for i in image:\n",
    "        for j in i:\n",
    "            pooled_image.append(max(i))\n",
    "            break\n",
    "            \n",
    "    return np.array(pooled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.325 , 0.6625, 1.    ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve2D() # Pooled 2-D convolution result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Famous CNN Architectures:\n",
    "\n",
    "* LeNet-5 by Yenn Lecun\n",
    "* AlexNet by Alex et al.\n",
    "* GoogLeNet by Szegedy at Google Research\n",
    "* ResNet by Kaiming He et al.\n",
    "\n",
    "Each of these Architecutres is essentially a set of designs of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
